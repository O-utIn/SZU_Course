{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子分割为单词: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "\n",
      "训练样本:\n",
      "样本 1: 前缀=['The'], 目标=quick\n",
      "样本 2: 前缀=['The', 'quick'], 目标=brown\n",
      "样本 3: 前缀=['The', 'quick', 'brown'], 目标=fox\n",
      "样本 4: 前缀=['The', 'quick', 'brown', 'fox'], 目标=jumps\n",
      "样本 5: 前缀=['The', 'quick', 'brown', 'fox', 'jumps'], 目标=over\n",
      "样本 6: 前缀=['The', 'quick', 'brown', 'fox', 'jumps', 'over'], 目标=the\n",
      "样本 7: 前缀=['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the'], 目标=lazy\n",
      "样本 8: 前缀=['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy'], 目标=dog\n",
      "样本 9: 前缀=['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'], 目标=.\n",
      "\n",
      "词汇表: ['.', 'The', 'brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'the']\n",
      "词汇表大小: 10\n",
      "单词到索引的映射:\n",
      "  '.': 0\n",
      "  'The': 1\n",
      "  'brown': 2\n",
      "  'dog': 3\n",
      "  'fox': 4\n",
      "  'jumps': 5\n",
      "  'lazy': 6\n",
      "  'over': 7\n",
      "  'quick': 8\n",
      "  'the': 9\n",
      "轮次 100/1000, 平均损失: 2.2499\n",
      "轮次 200/1000, 平均损失: 2.1991\n",
      "轮次 300/1000, 平均损失: 1.9324\n",
      "轮次 400/1000, 平均损失: 0.5396\n",
      "轮次 500/1000, 平均损失: 0.1114\n",
      "轮次 600/1000, 平均损失: 0.0528\n",
      "轮次 700/1000, 平均损失: 0.0335\n",
      "轮次 800/1000, 平均损失: 0.0243\n",
      "轮次 900/1000, 平均损失: 0.0189\n",
      "轮次 1000/1000, 平均损失: 0.0154\n",
      "\n",
      "预测测试及独热编码:\n",
      "\n",
      "输入前缀: ['The']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "预测: quick, 实际: quick → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "预测: brown, 实际: brown → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "预测: fox, 实际: fox → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown', 'fox']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'fox' 的独热编码: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "预测: jumps, 实际: jumps → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown', 'fox', 'jumps']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'fox' 的独热编码: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  单词 'jumps' 的独热编码: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "预测: over, 实际: over → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown', 'fox', 'jumps', 'over']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'fox' 的独热编码: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  单词 'jumps' 的独热编码: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  单词 'over' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "预测: the, 实际: the → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'fox' 的独热编码: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  单词 'jumps' 的独热编码: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  单词 'over' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  单词 'the' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "预测: lazy, 实际: lazy → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'fox' 的独热编码: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  单词 'jumps' 的独热编码: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  单词 'over' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  单词 'the' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  单词 'lazy' 的独热编码: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "预测: dog, 实际: dog → 正确\n",
      "\n",
      "输入前缀: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "  单词 'The' 的独热编码: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'quick' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  单词 'brown' 的独热编码: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  单词 'fox' 的独热编码: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  单词 'jumps' 的独热编码: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  单词 'over' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  单词 'the' 的独热编码: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  单词 'lazy' 的独热编码: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  单词 'dog' 的独热编码: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "预测: ., 实际: . → 正确\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 准备数据\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "# 按单词分割句子，保留标点符号\n",
    "words = re.findall(r\"\\b\\w+\\b|[^\\w\\s]\", sentence)\n",
    "print(f\"句子分割为单词: {words}\")\n",
    "\n",
    "# 创建多个训练样本：每个样本是(前缀序列, 目标单词)\n",
    "samples = []\n",
    "for i in range(1, len(words)):\n",
    "    prefix = words[:i]  # 前缀序列\n",
    "    target = words[i]   # 目标单词\n",
    "    samples.append((prefix, target))\n",
    "\n",
    "print(\"\\n训练样本:\")\n",
    "for i, (prefix, target) in enumerate(samples):\n",
    "    print(f\"样本 {i+1}: 前缀={prefix}, 目标={target}\")\n",
    "\n",
    "# 提取所有唯一单词并创建映射\n",
    "vocab = sorted(list(set(words)))\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx_to_word = {i: word for i, word in enumerate(vocab)}\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f\"\\n词汇表: {vocab}\")\n",
    "print(f\"词汇表大小: {vocab_size}\")\n",
    "print(\"单词到索引的映射:\")\n",
    "for word, idx in word_to_idx.items():\n",
    "    print(f\"  '{word}': {idx}\")\n",
    "\n",
    "# 将单词序列转换为独热编码，并输出独热编码\n",
    "def words_to_one_hot(words_seq, vocab_size, word_to_idx, verbose=False):\n",
    "    \"\"\"将单词序列转换为独热编码序列\"\"\"\n",
    "    one_hot_vectors = []\n",
    "    for word in words_seq:\n",
    "        # 创建独热向量\n",
    "        one_hot = np.eye(vocab_size)[word_to_idx[word]]\n",
    "        one_hot_vectors.append(one_hot)\n",
    "        \n",
    "        # 如果需要，输出独热编码信息\n",
    "        if verbose:\n",
    "            idx = word_to_idx[word]\n",
    "            print(f\"  单词 '{word}' 的独热编码: {one_hot}\")\n",
    "    \n",
    "    return np.array(one_hot_vectors)\n",
    "\n",
    "# 初始化RNN权重\n",
    "hidden_size = 16  # 隐藏层大小\n",
    "\n",
    "# 输入到隐藏层的权重 (词汇表大小 × 隐藏层大小)\n",
    "W1 = np.random.randn(vocab_size, hidden_size) * 0.01\n",
    "# 隐藏层到隐藏层的权重 (隐藏层大小 × 隐藏层大小)\n",
    "W2 = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "# 隐藏层到输出层的权重 (隐藏层大小 × 词汇表大小)\n",
    "W3 = np.random.randn(hidden_size, vocab_size) * 0.01\n",
    "\n",
    "# 偏置项\n",
    "b1 = np.zeros((1, hidden_size))  # 输入层到隐藏层的偏置\n",
    "b2 = np.zeros((1, vocab_size))   # 隐藏层到输出层的偏置\n",
    "\n",
    "# RNN前向传播\n",
    "def rnn_forward(inputs, W1, W2, W3, b1, b2, hidden_size):\n",
    "    \"\"\"\n",
    "    RNN前向传播\n",
    "    inputs: 输入序列的独热编码，形状为(seq_len, vocab_size)\n",
    "    返回: 输出序列，隐藏状态序列\n",
    "    \"\"\"\n",
    "    seq_len, vocab_size = inputs.shape\n",
    "    hidden_states = np.zeros((seq_len + 1, hidden_size))  # 初始隐藏状态为0\n",
    "    outputs = np.zeros((seq_len, vocab_size))\n",
    "    \n",
    "    for t in range(seq_len):\n",
    "        # 计算当前时间步的隐藏状态\n",
    "        hidden_states[t+1] = np.tanh(\n",
    "            np.dot(inputs[t], W1) + \n",
    "            np.dot(hidden_states[t], W2) + \n",
    "            b1\n",
    "        )\n",
    "        # 计算当前时间步的输出\n",
    "        outputs[t] = np.dot(hidden_states[t+1], W3) + b2\n",
    "    \n",
    "    return outputs, hidden_states\n",
    "\n",
    "# 交叉熵损失函数\n",
    "def cross_entropy_loss(predictions, target):\n",
    "    \"\"\"计算交叉熵损失\"\"\"\n",
    "    exp_preds = np.exp(predictions - np.max(predictions))  # 防止数值溢出\n",
    "    probs = exp_preds / np.sum(exp_preds)\n",
    "    loss = -np.sum(target * np.log(probs + 1e-10))  # 加小值防止log(0)\n",
    "    return loss, probs\n",
    "\n",
    "# 反向传播\n",
    "def rnn_backward(inputs, outputs, hidden_states, target, W2, W3, hidden_size):\n",
    "    \"\"\"RNN反向传播计算梯度\"\"\"\n",
    "    seq_len, vocab_size = inputs.shape\n",
    "    dW1 = np.zeros_like(W1)\n",
    "    dW2 = np.zeros_like(W2)\n",
    "    dW3 = np.zeros_like(W3)\n",
    "    db1 = np.zeros_like(b1)\n",
    "    db2 = np.zeros_like(b2)\n",
    "    \n",
    "    # 最后一个时间步的输出误差\n",
    "    exp_preds = np.exp(outputs[-1] - np.max(outputs[-1]))\n",
    "    probs = exp_preds / np.sum(exp_preds)\n",
    "    delta_output = probs - target  # 输出层误差\n",
    "    \n",
    "    # 隐藏层误差\n",
    "    delta_hidden = np.dot(delta_output, W3.T) * (1 - hidden_states[-1]**2)\n",
    "    delta_hidden = delta_hidden.reshape(1, -1)  # 确保是二维数组\n",
    "    \n",
    "    # 计算梯度\n",
    "    dW3 += np.dot(hidden_states[-1].reshape(-1, 1), delta_output.reshape(1, -1))\n",
    "    db2 += delta_output\n",
    "    \n",
    "    dW1 += np.dot(inputs[-1].reshape(-1, 1), delta_hidden)\n",
    "    dW2 += np.dot(hidden_states[-2].reshape(-1, 1), delta_hidden)\n",
    "    db1 += delta_hidden\n",
    "    \n",
    "    return dW1, dW2, dW3, db1, db2\n",
    "\n",
    "# 训练模型\n",
    "learning_rate = 0.01\n",
    "epochs = 1000  # 训练轮次\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # 遍历所有样本进行训练\n",
    "    for prefix, target_word in samples:\n",
    "        # 准备输入和目标（训练时不打印独热编码，避免输出过多）\n",
    "        input_one_hot = words_to_one_hot(prefix, vocab_size, word_to_idx, verbose=False)\n",
    "        target_idx = word_to_idx[target_word]\n",
    "        target_one_hot = np.eye(vocab_size)[target_idx]\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs, hidden_states = rnn_forward(\n",
    "            input_one_hot, W1, W2, W3, b1, b2, hidden_size\n",
    "        )\n",
    "        final_output = outputs[-1]\n",
    "        \n",
    "        # 计算损失\n",
    "        loss, _ = cross_entropy_loss(final_output, target_one_hot)\n",
    "        total_loss += loss\n",
    "        \n",
    "        # 反向传播计算梯度\n",
    "        dW1, dW2, dW3, db1, db2 = rnn_backward(\n",
    "            input_one_hot, outputs, hidden_states, target_one_hot, W2, W3, hidden_size\n",
    "        )\n",
    "        \n",
    "        # 更新权重\n",
    "        W1 -= learning_rate * dW1\n",
    "        W2 -= learning_rate * dW2\n",
    "        W3 -= learning_rate * dW3\n",
    "        b1 -= learning_rate * db1\n",
    "        b2 -= learning_rate * db2\n",
    "    \n",
    "    # 每100轮打印一次损失\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"轮次 {epoch+1}/{epochs}, 平均损失: {total_loss/len(samples):.4f}\")\n",
    "\n",
    "# 测试模型预测结果\n",
    "print(\"\\n预测测试及独热编码:\")\n",
    "for prefix, target_word in samples:\n",
    "    print(f\"\\n输入前缀: {prefix}\")\n",
    "    # 生成独热编码并打印\n",
    "    input_one_hot = words_to_one_hot(prefix, vocab_size, word_to_idx, verbose=True)\n",
    "    \n",
    "    outputs, _ = rnn_forward(input_one_hot, W1, W2, W3, b1, b2, hidden_size)\n",
    "    final_output = outputs[-1]\n",
    "    \n",
    "    # 计算预测概率\n",
    "    _, probs = cross_entropy_loss(final_output, np.zeros(vocab_size))\n",
    "    predicted_idx = np.argmax(probs)\n",
    "    predicted_word = idx_to_word[predicted_idx]\n",
    "    \n",
    "    print(f\"预测: {predicted_word}, 实际: {target_word} → {'正确' if predicted_word == target_word else '错误'}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
